# Avikam1 LLM - Mod√®le de Langage pour Evilafo AI
#### Mod√®le Optimis√© pour les Sciences Quantitatives

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/downloads/)
[![MLflow](https://img.shields.io/badge/mlflow-%232C3E50.svg?logo=mlflow)](https://mlflow.org/)


**Avikam1-LLM** est un mod√®le de langage optimis√© pour deux principaux cas d‚Äôutilisation :
- **Sciences Quantitatives** : la finance quantitative, les math√©matiques, l'actuariat, l'informatique, et le trading haute fr√©quence.
- **Chatbot** : Interactions conversationnelles fluides avec des r√©ponses naturelles et contextuelles tel que [Evilafo AI](https://chat.evilafo.xyz).

Ce projet repose sur l'architecture **LLaMA-2**, avec des am√©liorations sp√©cifiques pour g√©rer des t√¢ches avanc√©es tout en restant accessible pour des conversations g√©n√©rales.


## Introduction

Ce projet a pour objectif de fournir un outil puissant et polyvalent √† destination des chercheurs et des professionnels √©voluant dans des domaines scientifiques exigeants. Avikam1-LLM allie des capacit√©s avanc√©es en sciences quantitatives telles que les math√©matiques et la finance √† une interface conversationnelle fluide, permettant une interaction naturelle et efficace. Le mod√®le est capable de traiter des √©quations complexes, d‚Äôanalyser des donn√©es financi√®res et de r√©pondre avec pr√©cision √† des questions techniques dans une large vari√©t√© de domaines.



## ‚ú® Fonctionnalit√©s Cl√©s

- üèóÔ∏è Fine-tuning efficace avec LoRA/QLoRA, faible consommation de ressources
- ‚ö° Inf√©rence rapide via Flash Attention 2
- üìä Tracking complet avec MLflow
- üê≥ Interface simple pour interagir avec le mod√®le via HTTP
- üìö Analyse de s√©ries temporelles et de donn√©es boursi√®res.


## üì¶ Installation

### Pr√©requis
- Python 3.10+
- GPU NVIDIA (recommand√©) ou CPU
- [PyTorch 2.0+](https://pytorch.org/)

```bash
# Clone du d√©p√¥t
git clone https://github.com/evilafo/avikam1-llm
cd avikam1-llm

# Installation des d√©pendances
pip install -r requirements.txt

# Pour le d√©veloppement
pip install -r requirements-dev.txt
```

## üèãÔ∏è Entra√Ænement

### Configuration
√âditez le fichier YAML :
```yaml
# configs/default.yaml
model:
  name: "evilafo/avikam1-7b"
  use_lora: true

training:
  learning_rate: 2e-5

quantitative_science:
  enable_math_mode: true
  enable_finance_mode: true
  max_sequence_length: 512
  numerical_precision: "float32"

lora:
  rank: 64
  alpha: 32
lora_target_modules:
    - "q_proj"
    - "v_proj"
    - "k_proj"
    - "o_proj"
  lora_dropout: 0.05

finance_data:
  time_series: true
  frequency: "1min"

metrics:
  perplexity: true
  bleu_score: true
  financial_accuracy: true
```

### Lancement
```bash
python train.py --config configs/lora.yaml
```

## üöÄ D√©ploiement

### API FastAPI
```bash
python src/inference/api.py
```
**Requ√™te exemple** :
```python
import requests
response = requests.post(
    "http://localhost:8000/generate",
    json={"prompt": "Explique la m√©canique quantique", "max_tokens": 150}
)
```

### Avec Docker
```dockerfile
FROM pytorch/pytorch:2.0.1-cuda11.7
COPY . /app
RUN pip install -r /app/requirements.txt
CMD ["python", "/app/src/inference/api.py"]
```

## üìä Monitoring avec MLflow
Visualisez les m√©triques :
```bash
mlflow ui --backend-store-uri file:///mlruns
```
![MLflow Dashboard](docs/assets/mlflow-black.svg)



## üèÜ Performances
| M√©trique | Valeur |
|----------|--------|
| MMLU (Knowledge) | 65% |
| GSM8K (Math) | 58% |
| Latence (T4 GPU) | 23 tokens/s |

## ü§ù Contribution
1. Forkez le projet
2. Cr√©ez une branche (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commitez (`git commit -m 'Add nouvelle fonctionnalite'`)
4. Pushez (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrez une Pull Request

## üìú Licence
Apache 2.0 - Voir [LICENSE](LICENSE)

## üìû Contact
√âquipe EvilaFo - [evil2846@gmail.com](mailto:evil2846@gmail.com)

---
